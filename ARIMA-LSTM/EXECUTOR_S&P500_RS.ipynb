{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ARIMA_LSTM_FUNCTIONS_REAL import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENS = 'RANDOM_SEARCH_1'\n",
    "PATH = F'S&P500/Sensitivity Analysis/{SENS}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SnP_ARIMA = get_data_ARIMA(index_symbol=\"^GSPC\", start=\"1996-01-17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_bars = 1000\n",
    "validation_bars = 250\n",
    "testing_bars = 250\n",
    "\n",
    "p_max = 6\n",
    "q_max = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(f'./Results/{PATH}/Visualisations/ARIMA_resids.csv') == True:\n",
    "    ARIMA_resids = pd.read_csv(f'./Results/{PATH}/Visualisations/ARIMA_resids.csv')\n",
    "    print(f'ARIMA resids results already exits')\n",
    "else: \n",
    "    model_predictions_SnP, train_data_SnP, test_validation_data_SnP = main_arima(p_max, q_max, df_SnP_ARIMA, lookback_bars, validation_bars, testing_bars)\n",
    "    df_test_SnP_ARIMA = pd.concat(test_validation_data_SnP, axis=0)\n",
    "    ARIMA_resids = df_test_SnP_ARIMA['Close'] - model_predictions_SnP\n",
    "    \n",
    "    if not os.path.exists(f'./Results/{PATH}/Visualisations/'):\n",
    "        os.makedirs(f'./Results/{PATH}/Visualisations/')\n",
    "    ARIMA_resids.to_csv(f'./Results/{PATH}/Visualisations/ARIMA_resids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading data\n",
    "df_SnP = get_data(index_symbol=\"^GSPC\")\n",
    "df_ViX = get_data(index_symbol='^VIX')\n",
    "\n",
    "# setting data\n",
    "df_SnP['Vix_Close'] = df_ViX['Close']\n",
    "df_SnP['stock_returns'] = df_SnP['Close'].pct_change().dropna()\n",
    "df_SnP['ARIMA_residuals'] = ARIMA_resids.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preperation \n",
    "values = df_SnP.values.astype('float32')\n",
    "\n",
    "values_X = values[:, [3,5,6,8]] \n",
    "values_Y = values[:, 3]\n",
    "\n",
    "# scaling data\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_Y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "S_C_X = scaler_X.fit_transform(values_X)\n",
    "S_C_Y = scaler_Y.fit_transform(values_Y.reshape(-1,1))\n",
    "\n",
    "S_C_X = pd.DataFrame(S_C_X)\n",
    "S_C_Y = pd.DataFrame(S_C_Y)\n",
    "\n",
    "scaled_values_X_7, scaled_values_Y_7 = create_dataset(S_C_X[14:], S_C_Y[14:], 7)\n",
    "scaled_values_X_14, scaled_values_Y_14 = create_dataset(S_C_X[7:], S_C_Y[7:], 14)\n",
    "scaled_values_X_21, scaled_values_Y_21 = create_dataset(S_C_X, S_C_Y, 21)\n",
    "\n",
    "datasets = {\n",
    "    7: (scaled_values_X_7, scaled_values_Y_7), \n",
    "    14: (scaled_values_X_14, scaled_values_Y_14),\n",
    "    21: (scaled_values_X_21, scaled_values_Y_21)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "patience = 10\n",
    "\n",
    "lookback_bars = 1000\n",
    "validation_bars = 250\n",
    "testing_bars = 250\n",
    "NUM_TRIAL = 20\n",
    "\n",
    "TRANSACTION_COST = (0.2/100) #(0.1/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNC_CLASS_TNR = HyperparameterTuner(datasets, lookback_bars, validation_bars, testing_bars, PATH, epochs, patience, NUM_TRIAL)\n",
    "\n",
    "# TUNER = FUNC_CLASS_TNR.hyperparameter_tuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best model for the Long-Only strategy based on the IR2 metric\n",
    "\n",
    "# df_LO = find_best_model_LO(datasets, lookback_bars, validation_bars, testing_bars, PATH, scaler_Y, TRANSACTION_COST, NUM_TRIAL) #change bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LO.to_csv(f'./Best_Models/{PATH}/df_copy_LO.csv', index=False)\n",
    "DF_COPY_LO = pd.read_csv(f'./Best_Models/{PATH}/df_copy_LO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = DF_COPY_LO.groupby('id_')\n",
    "\n",
    "# Initialize empty lists to store results\n",
    "id_list = []\n",
    "model_list = []\n",
    "\n",
    "# Define a weight for the proximity of 'IR_2_train_value' to 'IR_2_validation_value'\n",
    "train_validation_weight = 1  # Weight for the proximity of 'IR_2_train_value' to 'IR_2_validation_value'\n",
    "loss_weight = 0.8\n",
    "\n",
    "# Iterate through each group and find the model_num based on the custom criterion\n",
    "for id_, group in grouped:\n",
    "    # Calculate the custom score based on the weight\n",
    "    group['custom_score'] = abs(group['IR_2_validation_value'] - group['IR_2_train_value'])\n",
    "    group['custom_score'] = np.where(group['IR_2_validation_value']==0, np.nan, group['custom_score'])\n",
    "    \n",
    "    # Find the row with the highest custom score\n",
    "    try:\n",
    "        best_model_row = group.loc[group['custom_score'].idxmin()]['model_num']\n",
    "    except:\n",
    "        best_model_row = 'model_0'\n",
    "\n",
    "    \n",
    "    id_list.append(id_)\n",
    "    model_list.append(best_model_row)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "result_df_LO = pd.DataFrame({'id_': id_list, 'model_num': model_list})\n",
    "\n",
    "# Convert 'id_' column to numeric and then sort\n",
    "result_df_LO['id_'] = result_df_LO['id_'].str.replace('id_', '').astype(int)\n",
    "result_df_LO.sort_values(by='id_', inplace=True)\n",
    "\n",
    "# Convert 'id_' column back to string format\n",
    "result_df_LO['id_'] = 'id_' + result_df_LO['id_'].astype(str)\n",
    "result_df_LO = result_df_LO.reset_index(drop=True)\n",
    "\n",
    "print(result_df_LO)\n",
    "\n",
    "### THE BEST SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = datasets\n",
    "stock_name = PATH\n",
    "\n",
    "ranges = list(range(lookback_bars, len(DATASETS[21][0]) - testing_bars, validation_bars))\n",
    "for i in range(0, len(ranges)): \n",
    "    \n",
    "    if path.exists(f'./Best_Models/{stock_name}/Long-Only/model_ID_{i}.h5') == True:\n",
    "        print(f'[SECTION_1 --> id_{i}] path exits') \n",
    "\n",
    "    else:\n",
    "        best_hyperparameters_index = result_df_LO['model_num'][i][6:]\n",
    "        \n",
    "        src_path = f'./Hyperparameter_tunning/{stock_name}/HP_Grid_Search_{i}/model_GS_{best_hyperparameters_index}.h5'\n",
    "        pre_dst_path = f'./Best_Models/{stock_name}/Long-Only'\n",
    "        if not os.path.exists(pre_dst_path):\n",
    "            os.makedirs(pre_dst_path)\n",
    "        dst_path = pre_dst_path + f'/model_ID_{i}.h5'\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        print(f'File Moved --> ID_{i}')\n",
    "    \n",
    "    print(f\"id_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Y_LO, test_model_predictions_LO = predict_LSTM(datasets, lookback_bars, validation_bars, testing_bars, f'{PATH}/Long-Only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Y_LO = np.concatenate(TEST_Y_LO)\n",
    "y_pred_test_LO = np.concatenate(test_model_predictions_LO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_test_LO = scaler_Y.inverse_transform(TEST_Y_LO.reshape(-1,1)).flatten()\n",
    "inv_y_pred_test_LO = scaler_Y.inverse_transform(y_pred_test_LO).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = lookback_bars+validation_bars+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv_y_test_LO = pd.DataFrame(data={'Date': df_SnP.index[num:(len(inv_y_test_LO)+num)], 'inv_y__test': inv_y_test_LO})\n",
    "df_inv_y_pred_test_LO = pd.DataFrame(data={'Date': df_SnP.index[num:(len(inv_y_test_LO)+num)], 'inv_y_pred_test': inv_y_pred_test_LO})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(df_inv_y_test_LO['inv_y__test'], df_inv_y_pred_test_LO['inv_y_pred_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_LSTM(df_index=df_SnP, df_test=df_inv_y_test_LO, df_predictions=df_inv_y_pred_test_LO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_LO = np.where(df_inv_y_pred_test_LO['inv_y_pred_test'].shift(-1)>df_inv_y_test_LO['inv_y__test'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve = df_SnP[['stock_returns', 'Close']]\n",
    "df_Equity_Curve.loc[:, 'return'] = df_SnP.loc[:, 'stock_returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve = df_Equity_Curve[num:len(inv_y_test_LO)+num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve['strat_return'] = df_Equity_Curve['Close'].pct_change().dropna()\n",
    "df_Equity_Curve['bnh_return'] = df_Equity_Curve['Close'].pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve['position'] = position_LO\n",
    "df_Equity_Curve = transaction_cost(df_Equity_Curve, TRANSACTION_COST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve[\"strategy\"] = (df_Equity_Curve[\"strat_return\"] * df_Equity_Curve['position'].shift(1))\n",
    "df_Equity_Curve[\"strategy\"] = (1+df_Equity_Curve[\"strategy\"].fillna(0)).cumprod()\n",
    "\n",
    "df_Equity_Curve['buy_n_hold'] = (1 + df_Equity_Curve['bnh_return'].fillna(0)).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_strategies(df_Equity_Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve['position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki(np.array(df_Equity_Curve['buy_n_hold'].values), 'Equity_Curve_BuyAndHold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki(np.array(df_Equity_Curve['strategy'].values), 'Equity_Curve_strategii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porownanie(np.array(df_Equity_Curve['strategy'].values), np.array(df_Equity_Curve['buy_n_hold'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENS_SENS = 'SENS_0A'\n",
    "PATH_SNES = F'S&P500/Sensitivity Analysis/{SENS_SENS}'\n",
    "\n",
    "STOCK_NAME_FOLDER = f'./Results/{PATH_SNES}/Visualisations'\n",
    "\n",
    "if not os.path.exists(STOCK_NAME_FOLDER):\n",
    "    os.makedirs(STOCK_NAME_FOLDER)\n",
    "\n",
    "df_Equity_Curve.to_csv(f'{STOCK_NAME_FOLDER}/df_EC_LO_MAIN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the best model for the Long-Only strategy based on the IR2 metric\n",
    "\n",
    "# df_LS = find_best_model_LS(datasets, lookback_bars, validation_bars, testing_bars, PATH, scaler_Y, TRANSACTION_COST, NUM_TRIAL) #change bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LS.to_csv(f'./Best_Models/{PATH}/df_copy_LS.csv', index=False)\n",
    "DF_COPY_LS = pd.read_csv(f'./Best_Models/{PATH}/df_copy_LS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = DF_COPY_LS.groupby('id_')\n",
    "\n",
    "# Initialize empty lists to store results\n",
    "id_list = []\n",
    "model_list = []\n",
    "\n",
    "# Define a weight for the proximity of 'IR_2_train_value' to 'IR_2_validation_value'\n",
    "train_validation_weight = 1  # Weight for the proximity of 'IR_2_train_value' to 'IR_2_validation_value'\n",
    "loss_weight = 0.8\n",
    "\n",
    "# Iterate through each group and find the model_num based on the custom criterion\n",
    "for id_, group in grouped:\n",
    "    # Calculate the custom score based on the weight\n",
    "    group['custom_score'] = abs(group['IR_2_validation_value'] - group['IR_2_train_value'])\n",
    "    group['custom_score'] = np.where(group['IR_2_validation_value']==0, np.nan, group['custom_score'])\n",
    "    \n",
    "    # Find the row with the highest custom score\n",
    "    try:\n",
    "        best_model_row = group.loc[group['custom_score'].idxmin()]['model_num']\n",
    "    except:\n",
    "        best_model_row = 'model_0'\n",
    "\n",
    "    \n",
    "    id_list.append(id_)\n",
    "    model_list.append(best_model_row)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "result_df_LS = pd.DataFrame({'id_': id_list, 'model_num': model_list})\n",
    "\n",
    "# Convert 'id_' column to numeric and then sort\n",
    "result_df_LS['id_'] = result_df_LS['id_'].str.replace('id_', '').astype(int)\n",
    "result_df_LS.sort_values(by='id_', inplace=True)\n",
    "\n",
    "# Convert 'id_' column back to string format\n",
    "result_df_LS['id_'] = 'id_' + result_df_LS['id_'].astype(str)\n",
    "result_df_LS = result_df_LS.reset_index(drop=True)\n",
    "\n",
    "print(result_df_LS)\n",
    "\n",
    "### THE BEST SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = datasets\n",
    "stock_name = PATH\n",
    "\n",
    "ranges = list(range(lookback_bars, len(DATASETS[21][0]) - testing_bars, validation_bars))\n",
    "for i in range(0, len(ranges)): \n",
    "    \n",
    "    if path.exists(f'./Best_Models/{stock_name}/Long-Short/model_ID_{i}.h5') == True:\n",
    "        print(f'[SECTION_1 --> id_{i}] path exits') \n",
    "\n",
    "    else:\n",
    "        best_hyperparameters_index = result_df_LS['model_num'][i][6:]\n",
    "        \n",
    "        src_path = f'./Hyperparameter_tunning/{stock_name}/HP_Grid_Search_{i}/model_GS_{best_hyperparameters_index}.h5'\n",
    "        pre_dst_path = f'./Best_Models/{stock_name}/Long-Short'\n",
    "        if not os.path.exists(pre_dst_path):\n",
    "            os.makedirs(pre_dst_path)\n",
    "        dst_path = pre_dst_path + f'/model_ID_{i}.h5'\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "        print(f'File Moved --> ID_{i}')\n",
    "    \n",
    "    print(f\"id_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Y_LS, test_model_predictions_LS = predict_LSTM(datasets, lookback_bars, validation_bars, testing_bars, f'{PATH}/Long-Short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Y_LS = np.concatenate(TEST_Y_LS)\n",
    "y_pred_test_LS = np.concatenate(test_model_predictions_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_test_LS = scaler_Y.inverse_transform(TEST_Y_LS.reshape(-1,1))\n",
    "inv_y_pred_test_LS = scaler_Y.inverse_transform(y_pred_test_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_y_test_LS = inv_y_test_LS.flatten()\n",
    "inv_y_pred_test_LS = inv_y_pred_test_LS.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = lookback_bars+validation_bars+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv_y_test_LS = pd.DataFrame(data={'Date': df_SnP.index[num:(len(inv_y_test_LS)+num)], 'inv_y__test': inv_y_test_LS})\n",
    "df_inv_y_pred_test_LS = pd.DataFrame(data={'Date': df_SnP.index[num:(len(inv_y_test_LS)+num)], 'inv_y_pred_test': inv_y_pred_test_LS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(df_inv_y_test_LS['inv_y__test'], df_inv_y_pred_test_LS['inv_y_pred_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_LSTM(df_index=df_SnP, df_test=df_inv_y_test_LS, df_predictions=df_inv_y_pred_test_LS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position_LO = (test_model_predictions_LO>0.5).astype(int)\n",
    "position_LS = np.where(df_inv_y_pred_test_LS['inv_y_pred_test'].shift(-1)>df_inv_y_test_LS['inv_y__test'],1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS = df_SnP[['stock_returns', 'Close']]\n",
    "df_Equity_Curve_LS.loc[:, 'return'] = df_SnP.loc[:, 'stock_returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS = df_Equity_Curve_LS[num:len(inv_y_test_LS)+num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS['strat_return'] = df_Equity_Curve_LS['Close'].pct_change().dropna()\n",
    "df_Equity_Curve_LS['bnh_return'] = df_Equity_Curve_LS['Close'].pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS['position'] = position_LS\n",
    "df_Equity_Curve_LS = transaction_cost(df_Equity_Curve_LS, TRANSACTION_COST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS[\"strategy\"] = (df_Equity_Curve_LS[\"strat_return\"] * df_Equity_Curve_LS['position'].shift(1))\n",
    "df_Equity_Curve_LS[\"strategy\"] = (1+df_Equity_Curve_LS[\"strategy\"].fillna(0)).cumprod()\n",
    "\n",
    "df_Equity_Curve_LS['buy_n_hold'] = (1 + df_Equity_Curve_LS['stock_returns'].fillna(0)).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_strategies(df_Equity_Curve_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Equity_Curve_LS['position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki(np.array(df_Equity_Curve_LS['buy_n_hold'].values), 'Equity_Curve_BuyAndHold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wyniki(np.array(df_Equity_Curve_LS['strategy'].values), 'Equity_Curve_strategii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porownanie(np.array(df_Equity_Curve_LS['strategy'].values), np.array(df_Equity_Curve_LS['buy_n_hold'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO CSV - SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENS_SENS = 'SENS_0A'\n",
    "PATH_SNES = F'S&P500/Sensitivity Analysis/{SENS_SENS}'\n",
    "\n",
    "STOCK_NAME_FOLDER = f'./Results/{PATH_SNES}/Visualisations'\n",
    "\n",
    "if not os.path.exists(STOCK_NAME_FOLDER):\n",
    "    os.makedirs(STOCK_NAME_FOLDER)\n",
    "    \n",
    "df_Equity_Curve_LS.to_csv(f'{STOCK_NAME_FOLDER}/df_EC_LS_MAIN.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
